{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ab762d73",
   "metadata": {},
   "source": [
    "## Assistants API - Function Calling\n",
    "\n",
    "An assistant is a purpose-built AI that has specific instructions, leverages extra knowledge, and can call models and tools to perform tasks.\n",
    "\n",
    "https://platform.openai.com/docs/assistants/tools/function-calling\n",
    "\n",
    "https://cookbook.openai.com/examples/assistants_api_overview_python\n",
    "\n",
    "https://dev.to/esponges/build-the-new-openai-assistant-with-function-calling-52f5\n",
    "\n",
    "https://community.openai.com/t/function-calling-with-assistants-api/488259/2\n",
    "\n",
    "https://community.openai.com/t/function-calling-with-assistants-api/488259\n",
    "\n",
    "https://dev.to/airtai/function-calling-and-code-interpretation-with-openais-assistant-api-a-quick-and-simple-tutorial-5ce5\n",
    "\n",
    "https://cobusgreyling.medium.com/what-are-openai-assistant-function-tools-exactly-06ef8e39b7bd\n",
    "\n",
    "Watch:\n",
    "\n",
    "https://www.youtube.com/watch?v=BV-_5_r46kE&t=0s\n",
    "\n",
    "https://www.youtube.com/watch?v=SaJxbuKehpc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "86dba3cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import json\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "_: bool = load_dotenv(find_dotenv())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b2462f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "client: OpenAI = OpenAI()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc158142",
   "metadata": {},
   "source": [
    "### Function calling\n",
    "\n",
    "Similar to the Chat Completions API, the Assistants API supports function calling. Function calling allows you to describe functions to the Assistants and have it intelligently return the functions that need to be called along with their arguments. The Assistants API will pause execution during a Run when it invokes functions, and you can supply the results of the function call back to continue the Run execution.\n",
    "\n",
    "##### Step 0: Define functions\n",
    "\n",
    "First, define your functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d599fba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# example dummy function hard coded to return the some weather\n",
    "\n",
    "# In production, this could be your backend api or an external api\n",
    "\n",
    "def getCurrentWeather(location: str, unit: str = 'fahrenheit') -> str | dict | None:\n",
    "    \"\"\"get a current weather in a given location\"\"\"\n",
    "    \n",
    "    if 'tokyo' in location.lower():\n",
    "        return json.dumps( {\"location\": \"tokyo\", \"temperature\": \"10\", \"unit\": \"celsius\"} )\n",
    "    elif 'loas Angeles' in location.lower():\n",
    "        return json.dumps( {\"location\": \"San Francisco\", \"temperature\": \"72\", \"unit\": \"fahrenheit\"} )\n",
    "    elif 'paris' in location.lower():\n",
    "        return json.dumps( {\"location\": \"paris\", \"temperature\": \"22\", \"unit\": \"celsius\"} )\n",
    "    else:\n",
    "        return json.dumps( {\"location\": location, \"temperature\": \"unknown\"})\n",
    "    \n",
    "    \n",
    "def getNickName(location: str) -> str:\n",
    "    \"\"\"Get a nickname of a city\"\"\"\n",
    "    \n",
    "    if \"tokyo\" in location.lower():\n",
    "        return \"tk\"\n",
    "    elif \"los angeles\" in location.lower():\n",
    "        return \"la\"\n",
    "    elif \"paris\" in location.lower():\n",
    "        return \"py\"\n",
    "    else:\n",
    "        return location\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8a67103",
   "metadata": {},
   "source": [
    "##### Step 1: Create an Assistant and register/report your functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "835ccd29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def show_json(message, obj) -> str:\n",
    "    display(message, json.loads(obj.model_dump_json()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5042bd76",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai.types.beta.assistant import Assistant\n",
    "\n",
    "assistant: Assistant = client.beta.assistants.create(\n",
    "    instructions='You are a weather bot. Use the provided functions to answer questions.',\n",
    "    model='gpt-3.5-turbo-1106',\n",
    "    tools=[\n",
    "        {\n",
    "            \"type\", \"function\",\n",
    "            \"function\": {\n",
    "                \"name\": \"getCurrentWeather\",\n",
    "                \"description\": \"Get the weather in location\",\n",
    "                \"parameters\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"location\": {\"type\": \"string\", \"description\": \"The city and state eg. San Francisco\"},\n",
    "                        \"unit\": {\"type\": \"string\", \"enum\": [\"celsius\", \"fahrenheit\"]}\n",
    "                    },\n",
    "                    \"required\": [\"location\"]\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"type\", \"function\",\n",
    "            \"function\": {\n",
    "                \"name\": \"getNickName\",\n",
    "                \"description\": \"Get the nickname of a city\",\n",
    "                \"parameters\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"location\": {\"type\": \"string\", \"description\": \"The city and state eg. San Francisco\"},\n",
    "                        \"unit\": {\"type\": \"string\", \"enum\": [\"celsius\", \"fahrenheit\"]}\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea6f7385",
   "metadata": {},
   "source": [
    "##### Step 2: Create a Thread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1646c9dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai.types.beta.thread import Thread\n",
    "\n",
    "thread: Thread = client.beta.threads.create()\n",
    "\n",
    "print(thread)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63b3dba3",
   "metadata": {},
   "source": [
    "##### Step 3: Add a Message to a Thread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai.types.beta.threads.thread_message import ThreadMessage\n",
    "\n",
    "# first request\n",
    "\n",
    "message: list[ThreadMessage] = client.beta.threads.messages.create(\n",
    "    thread_id=thread.id,\n",
    "    role=\"user\",\n",
    "    content=\"How is the weather in Los Angeles?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "646f35c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict(message)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1deb84dc",
   "metadata": {},
   "source": [
    "##### Step 4: Run the Assistant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb67927a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai.types.beta.threads.run import Run\n",
    "\n",
    "run: Run = client.beta.threads.runs.create(\n",
    "    thread_id=thread.id,\n",
    "    assistant_id=assistant.id\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ebf4bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict(run)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5661c80f",
   "metadata": {},
   "source": [
    "### Run Life Cycle\n",
    "\n",
    "<img src='./diagram.png' alt='run life cycle of thread' />\n",
    "\n",
    "#### STATUS DEFINITION\n",
    "\n",
    "https://platform.openai.com/docs/assistants/how-it-works/runs-and-run-steps\n",
    "\n",
    "##### queued:\n",
    "\n",
    "When Runs are first created or when you complete the required_action, they are moved to a queued status. They should almost immediately move to in_progress.\n",
    "\n",
    "##### in_progress:\n",
    "\n",
    "While in_progress, the Assistant uses the model and tools to perform steps. You can view progress being made by the Run by examining the Run Steps.\n",
    "\n",
    "##### completed:\n",
    "\n",
    "The Run successfully completed! You can now view all Messages the Assistant added to the Thread, and all the steps the Run took. You can also continue the conversation by adding more user Messages to the Thread and creating another Run.\n",
    "\n",
    "##### requires_action:\n",
    "\n",
    "When using the Function calling tool, the Run will move to a required_action state once the model determines the names and arguments of the functions to be called. You must then run those functions and submit the outputs before the run proceeds. If the outputs are not provided before the expires_at timestamp passes (roughly 10 mins past creation), the run will move to an expired status.\n",
    "\n",
    "##### expired:\n",
    "\n",
    "This happens when the function calling outputs were not submitted before expires_at and the run expires. Additionally, if the runs take too long to execute and go beyond the time stated in expires_at, our systems will expire the run.\n",
    "\n",
    "##### cancelling:\n",
    "\n",
    "You can attempt to cancel an in_progress run using the Cancel Run endpoint. Once the attempt to cancel succeeds, status of the Run moves to cancelled. Cancellation is attempted but not guaranteed. cancelled Run was successfully cancelled.\n",
    "\n",
    "failed:\n",
    "\n",
    "You can view the reason for the failure by looking at the last_error object in the Run. The timestamp for the failure will be recorded under failed_at.\n",
    "\n",
    "##### Polling for updates\n",
    "In order to keep the status of your run up to date, you will have to periodically retrieve the Run object. You can check the status of the run each time you retrieve the object to determine what your application should do next. We plan to add support for streaming to make this simpler in the near future.\n",
    "\n",
    "##### Thread locks\n",
    "When a Run is in_progress and not in a terminal state, the Thread is locked. This means that:\n",
    "\n",
    "New Messages cannot be added to the Thread.\n",
    "\n",
    "New Runs cannot be created on the Thread.\n",
    "\n",
    "##### Run steps\n",
    "\n",
    "<img src='./diagram-2.png' alt='run life cycle of thread' />\n",
    "\n",
    "Most of the interesting detail in the Run Step object lives in the step_details field. There can be two types of step details:\n",
    "\n",
    "1. message_creation: This Run Step is created when the Assistant creates a Message on the Thread.\n",
    "\n",
    "2. tool_calls: This Run Step is created when the Assistant calls a tool. Details around this are covered in the relevant sections of the Tools guide."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5614bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "available_functions = {\n",
    "    \"getCurrentWeather\": getCurrentWeather,\n",
    "    \"getNickName\": getNickName\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9822291c",
   "metadata": {},
   "outputs": [],
   "source": [
    "thread.id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd2e9bdd",
   "metadata": {},
   "source": [
    "##### Step 5: Polling for Updates and Calling Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "373298c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# loop until the run completes or requires actions\n",
    "\n",
    "while True:\n",
    "    \n",
    "    runStatus = client.beta.threads.runs.retrieve(thread_id=thread.id, run_id=run.id)\n",
    "    \n",
    "    # add run steps retrieval here for debugging\n",
    "    \n",
    "    run_steps = client.beta.threads.runs.steps.list(thread_id=thread.id, run_id=run.id)\n",
    "    \n",
    "    # show_json(\"run steps: \", run_steps)\n",
    "    \n",
    "    print(runStatus.status, '.....')\n",
    "    \n",
    "    # this means run is making a function call\n",
    "    \n",
    "    if runStatus.status == \"requires_action\":\n",
    "        \n",
    "        print(runStatus.status, '.....')\n",
    "        \n",
    "        print(\"status: \", \"requires_action\")\n",
    "        \n",
    "        show_json(\"submit_tools_output\", runStatus.required_action)\n",
    "        \n",
    "        if runStatus.required_action.submit_tool_outputs and runStatus.required_action.submit_tool_outputs.tool_calls:\n",
    "            \n",
    "            print(\"toolCalls presents\")\n",
    "            \n",
    "            toolCalls = runStatus.required_action.submit_tool_outputs.tool_calls\n",
    "            \n",
    "            tool_outputs = []\n",
    "            \n",
    "            for toolCall in toolCalls:\n",
    "                \n",
    "                function_name = toolCall.function.name\n",
    "                \n",
    "                function_args = json.loads(toolCall.function.arguments)\n",
    "                \n",
    "                if function_name in available_functions:\n",
    "                    \n",
    "                    function_to_call = available_functions[function_name]\n",
    "                    \n",
    "                    print(function_to_call, function_to_call.__name__ == \"getCurrentWeather\", \"=====================\")\n",
    "                    \n",
    "                    if function_to_call.__name__ == \"getCurrentWeather\":\n",
    "                        \n",
    "                        response = function_to_call(\n",
    "                            location = function_args.get(\"location\"),\n",
    "                            unit = function_args.get(\"unit\")\n",
    "                        )\n",
    "                        \n",
    "                        tool_outputs.append({\n",
    "                            \"tool_call_id\": toolCall.id,\n",
    "                            \"output\": response\n",
    "                        })\n",
    "                        \n",
    "                    elif function_to_call.__name__ == \"getNickName\":\n",
    "                        \n",
    "                        response = function_to_call(\n",
    "                            location = function_args.get(\"location\")\n",
    "                        )\n",
    "                        \n",
    "                        tool_outputs.append({\n",
    "                            \"tool_call_id\": toolCall.id,\n",
    "                            \"output\": response\n",
    "                        })\n",
    "                        \n",
    "            print(tool_outputs, '>>>>')\n",
    "            \n",
    "            # submit tool output and update the run\n",
    "            \n",
    "            client.beta.threads.runs.submit_tool_outputs(\n",
    "                thread_id=thread.id,\n",
    "                run_id=run.id,\n",
    "                tool_outputs=tool_outputs\n",
    "            )\n",
    "            \n",
    "    elif runStatus.status == \"completed\":\n",
    "        \n",
    "        # list the messages to get the response\n",
    "        \n",
    "        print(\"completed ........ logic\")\n",
    "        \n",
    "        messages: list[ThreadMessage] = client.beta.threads.messages.list(thread_id=thread.id)\n",
    "        \n",
    "        for message in messages.data:\n",
    "            \n",
    "            role_label == \"User\" if message.role == 'user' else \"Assistant\"\n",
    "            \n",
    "            message_content = message.content[0].text.value\n",
    "            \n",
    "            print(f\"{role_label}: {message_content}\\n\")\n",
    "            \n",
    "            break      # exit the loop after processing the completed run\n",
    "        \n",
    "    elif run.status == \"failed\":\n",
    "        \n",
    "        print(\"run failed\")\n",
    "        \n",
    "        break\n",
    "    \n",
    "    elif run.status in [\"in_progress\", \"queued\"]:\n",
    "        \n",
    "        print(f\"run is {run.status}. waiting...\")\n",
    "        \n",
    "        time.sleep(5)     # wait for 5 seconds before checking again\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        print(f\"unexpected status: {run.status}\")\n",
    "        \n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
